{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849f3958-229b-40a3-a3fd-478546f5a318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in scalar subtract\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import emcee\n",
    "import corner\n",
    "import os\n",
    "from mpl_toolkits.mplot3d import Axes3D  # for 3D plotting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn.cluster import DBSCAN  # for clustering the MCMC samples\n",
    "import plotly.express as px\n",
    "\n",
    "###############################################################################\n",
    "# DBSCAN cluster function (unchanged)\n",
    "###############################################################################\n",
    "def cluster_mcmc_samples(chain_samples, eps=0.1, min_samples=30):\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(chain_samples)\n",
    "    labels = clustering.labels_\n",
    "    clusters = []\n",
    "    for label in set(labels):\n",
    "        if label == -1:  # ignore noise points\n",
    "            continue\n",
    "        indices = np.where(labels == label)[0]\n",
    "        cluster_samples = chain_samples[indices]\n",
    "        mean = np.mean(cluster_samples, axis=0)\n",
    "        std = np.std(cluster_samples, axis=0)\n",
    "        clusters.append({\"mean\": mean, \"std\": std, \"n_samples\": len(cluster_samples), \"indices\": indices})\n",
    "    return clusters\n",
    "\n",
    "###############################################################################\n",
    "# Standard Gelman-Rubin convergence diagnostic for a set of chains.\n",
    "###############################################################################\n",
    "def gelman_rubin(chains):\n",
    "    \"\"\"\n",
    "    Computes the Gelman-Rubin statistic for a set of chains.\n",
    "    Input:\n",
    "      chains: numpy array with shape (n_steps, n_walkers, n_dim)\n",
    "    Returns:\n",
    "      rhat: numpy array of length n_dim with the R̂ values.\n",
    "    \"\"\"\n",
    "    n_steps, n_walkers, n_dim = chains.shape\n",
    "    rhat = np.empty(n_dim)\n",
    "    for d in range(n_dim):\n",
    "        # Get chain for parameter d: shape (n_steps, n_walkers)\n",
    "        chain_d = chains[:, :, d]\n",
    "        chain_means = np.mean(chain_d, axis=0)\n",
    "        overall_mean = np.mean(chain_means)\n",
    "        B = n_steps * np.var(chain_means, ddof=1)\n",
    "        W = np.mean(np.var(chain_d, axis=0, ddof=1))\n",
    "        Var_hat = ((n_steps - 1) / n_steps) * W + (B / n_steps)\n",
    "        rhat[d] = np.sqrt(Var_hat / W)\n",
    "    return rhat\n",
    "\n",
    "###############################################################################\n",
    "# Gelman-Rubin diagnostic computed on samples in one cluster\n",
    "###############################################################################\n",
    "def gelman_rubin_cluster(chain_post, cluster_indices, n_walkers):\n",
    "    \"\"\"\n",
    "    Compute Rhat for a given cluster. The cluster_indices are indices from the \n",
    "    flattened chain (from chain_post.reshape(-1, ndim)). This function re-groups \n",
    "    the samples by walker.\n",
    "\n",
    "    Parameters:\n",
    "      chain_post: numpy array of shape (n_steps, n_walkers, n_dim)\n",
    "      cluster_indices: 1D array of flattened indices (from DBSCAN clustering)\n",
    "      n_walkers: number of walkers (as in chain_post.shape[1])\n",
    "    \n",
    "    Returns:\n",
    "      rhat: R̂ values for this cluster (numpy array of length n_dim),\n",
    "            or None if insufficient samples/walkers.\n",
    "    \"\"\"\n",
    "    n_steps, n_walkers, n_dim = chain_post.shape\n",
    "\n",
    "    # Build a dictionary: for each walker, store a list of samples (in order of appearance).\n",
    "    samples_by_walker = {w: [] for w in range(n_walkers)}\n",
    "    \n",
    "    # Because the flattened chain was obtained with row-major order,\n",
    "    # each index i corresponds to: step = i // n_walkers, walker = i % n_walkers.\n",
    "    for idx in cluster_indices:\n",
    "        step = idx // n_walkers\n",
    "        walker = idx % n_walkers\n",
    "        samples_by_walker[walker].append(chain_post[step, walker, :])\n",
    "    \n",
    "    # Only keep walkers with at least 2 samples\n",
    "    valid_walkers = {w: np.array(samples) for w, samples in samples_by_walker.items() if len(samples) >= 2}\n",
    "    \n",
    "    if len(valid_walkers) < 2:\n",
    "        # Not enough chains in this cluster to compute Rhat\n",
    "        return None\n",
    "\n",
    "    # Truncate each walker's chain to the minimum number of samples found\n",
    "    min_samples = min(len(samples) for samples in valid_walkers.values())\n",
    "    # Build an array of shape (min_samples, n_valid_walkers, n_dim)\n",
    "    chains_cluster = []\n",
    "    for w in valid_walkers:\n",
    "        chain_w = valid_walkers[w][:min_samples]\n",
    "        chains_cluster.append(chain_w)\n",
    "    chains_cluster = np.stack(chains_cluster, axis=1)  # shape: (min_samples, n_valid_walkers, n_dim)\n",
    "    rhat = gelman_rubin(chains_cluster)\n",
    "    return rhat\n",
    "\n",
    "###############################################################################\n",
    "# Plot predicted vs. actual\n",
    "###############################################################################\n",
    "def plot_predicted_vs_actual(y_true, y_pred, model_name, target_names):\n",
    "    for i, target in enumerate(target_names):\n",
    "        plt.figure()\n",
    "        plt.scatter(y_true[:, i], y_pred[:, i], alpha=0.7)\n",
    "        plt.plot([min(y_true[:, i]), max(y_true[:, i])],\n",
    "                 [min(y_true[:, i]), max(y_true[:, i])], 'r--')\n",
    "        plt.xlabel(f\"Actual {target}\")\n",
    "        plt.ylabel(f\"Predicted {target}\")\n",
    "        plt.title(f\"{model_name} - Predicted vs. Actual: {target}\")\n",
    "        plt.show()\n",
    "\n",
    "###############################################################################\n",
    "# Get bin mask\n",
    "###############################################################################\n",
    "def get_bin_mask(df_all, period_bin, ecc_bin):\n",
    "    if period_bin == \"p1\":\n",
    "        period_mask = (df_all[\"ratio\"] >= 1.9) & (df_all[\"ratio\"] <= 1.99)\n",
    "    elif period_bin == \"p2\":\n",
    "        period_mask = (df_all[\"ratio\"] >= 2.01) & (df_all[\"ratio\"] <= 2.1)\n",
    "    elif period_bin == \"p3\":\n",
    "        period_mask = (df_all[\"ratio\"] >= 1.4) & (df_all[\"ratio\"] <= 1.49)\n",
    "    elif period_bin == \"p4\":\n",
    "        period_mask = (df_all[\"ratio\"] >= 1.51) & (df_all[\"ratio\"] <= 1.6)\n",
    "    elif period_bin == \"p5\":\n",
    "        period_mask = (df_all[\"ratio\"] >= 2.2) & (df_all[\"ratio\"] <= 2.5)\n",
    "    else:\n",
    "        period_mask = (df_all[\"ratio\"] > 2.5) & (df_all[\"ratio\"] <= 2.8)\n",
    "\n",
    "    if ecc_bin == \"e1\":\n",
    "        ecc_mask = (df_all[\"out_ecc\"] <= -2.0)\n",
    "    elif ecc_bin == \"e2\":\n",
    "        ecc_mask = (df_all[\"out_ecc\"] > -2.0) & (df_all[\"out_ecc\"] <= -1.5228)\n",
    "    else:\n",
    "        ecc_mask = (df_all[\"out_ecc\"] > -1.5228) & (df_all[\"out_ecc\"] <= np.log10(0.08))\n",
    "    return period_mask & ecc_mask\n",
    "\n",
    "###############################################################################\n",
    "# Build ModelB for a bin\n",
    "###############################################################################\n",
    "def build_modelB_for_bin(df_all, period_bin, ecc_bin):\n",
    "    print(f\"\\n=== build_modelB_for_bin => period='{period_bin}', eccentricity='{ecc_bin}'\")\n",
    "    mask_bin = get_bin_mask(df_all, period_bin, ecc_bin)\n",
    "    mask_amp = df_all[\"AmpP1\"] <= 500\n",
    "    df = df_all[mask_bin & mask_amp].copy()\n",
    "    if df.empty:\n",
    "        print(\"No data for this bin.\")\n",
    "        return None, None, None\n",
    "    featB = [\"star_m\", \"inn_p\", \"inn_m\", \"inn_ecc\", \"inn_inc\", \"inn_omega\", \"AmpP1\", \"DomP1\"]\n",
    "    targB = [\"out_m\", \"out_p\"]\n",
    "    df.dropna(subset=(featB + targB), inplace=True)\n",
    "    if df.empty or len(df) < 5:\n",
    "        print(\"Not enough data after dropping NA for this bin.\")\n",
    "        return None, None, None\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(df[featB], df[targB],\n",
    "                                                test_size=0.2, random_state=42)\n",
    "    scB = StandardScaler()\n",
    "    X_tr_sc = scB.fit_transform(X_tr)\n",
    "    X_val_sc = scB.transform(X_val)\n",
    "    rfB = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "    rfB.fit(X_tr_sc, y_tr)\n",
    "    y_pred_val = rfB.predict(X_val_sc)\n",
    "    plot_predicted_vs_actual(y_val.values, y_pred_val,\n",
    "                             f\"Model B ({period_bin}, {ecc_bin})\", targB)\n",
    "    mae_vals = []\n",
    "    rmse_vals = []\n",
    "    mafe_vals = []\n",
    "    r2_vals = []\n",
    "    for i, col_ in enumerate(targB):\n",
    "        mae_ = mean_absolute_error(y_val[col_], y_pred_val[:, i])\n",
    "        r2_  = r2_score(y_val[col_], y_pred_val[:, i])\n",
    "        rmse_ = np.sqrt(mean_squared_error(y_val[col_], y_pred_val[:, i]))\n",
    "        mafe_ = np.mean(np.abs((y_val[col_] - y_pred_val[:, i]) / (y_val[col_] + 1e-8)))\n",
    "        print(f\"ModelB({period_bin}, {ecc_bin}) - {col_}: MAE={mae_:.4f}, RMSE={rmse_:.4f}, MAFE={mafe_:.4f}, R2={r2_:.4f}\")\n",
    "        mae_vals.append(mae_)\n",
    "        rmse_vals.append(rmse_)\n",
    "        mafe_vals.append(mafe_)\n",
    "        r2_vals.append(r2_)\n",
    "    error_metrics_B = {\"MAE\": np.mean(mae_vals),\n",
    "                       \"RMSE\": np.mean(rmse_vals),\n",
    "                       \"MAFE\": np.mean(mafe_vals),\n",
    "                       \"R2\": np.mean(r2_vals)}\n",
    "    return rfB, scB, error_metrics_B\n",
    "\n",
    "###############################################################################\n",
    "# Build ModelA for a bin\n",
    "###############################################################################\n",
    "def build_modelA_for_bin(df_all, period_bin, ecc_bin):\n",
    "    print(f\"\\n=== build_modelA_for_bin => period='{period_bin}', eccentricity='{ecc_bin}' ===\")\n",
    "    featA = [\"star_m\", \"inn_p\", \"inn_m\", \"inn_ecc\", \"inn_inc\", \"inn_omega\",\n",
    "             \"out_p\", \"out_m\", \"out_ecc\", \"out_inc\", \"out_omega\"]\n",
    "    targA = [\"AmpP1\", \"DomP1\"]\n",
    "    mask_bin = get_bin_mask(df_all, period_bin, ecc_bin)\n",
    "    mask_amp = df_all[\"AmpP1\"] <= 500\n",
    "    df = df_all[mask_bin & mask_amp].copy()\n",
    "    if df.empty or len(df) < 5:\n",
    "        print(\"Not enough data for this bin.\")\n",
    "        return None, None, None\n",
    "    df.dropna(subset=(featA + targA), inplace=True)\n",
    "    if df.empty:\n",
    "        print(\"Not enough data after dropping NA for this bin.\")\n",
    "        return None, None, None\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(df[featA], df[targA],\n",
    "                                                test_size=0.2, random_state=42)\n",
    "    scA = StandardScaler()\n",
    "    X_tr_sc = scA.fit_transform(X_tr)\n",
    "    X_val_sc = scA.transform(X_val)\n",
    "    rfA = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "    rfA.fit(X_tr_sc, y_tr)\n",
    "    y_pred_val = rfA.predict(X_val_sc)\n",
    "    plot_predicted_vs_actual(y_val.values, y_pred_val,\n",
    "                             f\"Model A ({period_bin}, {ecc_bin})\", targA)\n",
    "    mae_vals = []\n",
    "    rmse_vals = []\n",
    "    mafe_vals = []\n",
    "    r2_vals = []\n",
    "    for i, col_ in enumerate(targA):\n",
    "        mae_ = mean_absolute_error(y_val[col_], y_pred_val[:, i])\n",
    "        r2_  = r2_score(y_val[col_], y_pred_val[:, i])\n",
    "        rmse_ = np.sqrt(mean_squared_error(y_val[col_], y_pred_val[:, i]))\n",
    "        mafe_ = np.mean(np.abs((y_val[col_] - y_pred_val[:, i]) / (y_val[col_] + 1e-8)))\n",
    "        print(f\"ModelA({period_bin}, {ecc_bin}) - {col_}: MAE={mae_:.4f}, RMSE={rmse_:.4f}, MAFE={mafe_:.4f}, R2={r2_:.4f}\")\n",
    "        mae_vals.append(mae_)\n",
    "        rmse_vals.append(rmse_)\n",
    "        mafe_vals.append(mafe_)\n",
    "        r2_vals.append(r2_)\n",
    "    error_metrics_A = {\"MAE\": np.mean(mae_vals),\n",
    "                       \"RMSE\": np.mean(rmse_vals),\n",
    "                       \"MAFE\": np.mean(mafe_vals),\n",
    "                       \"R2\": np.mean(r2_vals)}\n",
    "    return rfA, scA, error_metrics_A\n",
    "\n",
    "###############################################################################\n",
    "# LOG-PROB for MCMC\n",
    "###############################################################################\n",
    "def log_prob_3params_layer1(theta_, bin_name, param_fixed, modelA, scA, actual_amp, actual_freq):\n",
    "    newD = copy.deepcopy(param_fixed)\n",
    "    out_p = theta_[0]\n",
    "    out_e = theta_[1]  # in log scale\n",
    "    out_m = theta_[2]\n",
    "    newD[\"out_p\"]   = out_p\n",
    "    newD[\"out_ecc\"] = out_e\n",
    "    newD[\"out_m\"]   = out_m\n",
    "\n",
    "    # Period prior\n",
    "    if out_p < param_fixed[\"period_prior_min\"] or out_p > param_fixed[\"period_prior_max\"]:\n",
    "        return -np.inf\n",
    "    # ratio in correct bin\n",
    "    inner_p = newD[\"inn_p\"]\n",
    "    period_ratio = out_p / inner_p\n",
    "    if period_ratio < param_fixed[\"period_bin_min\"] or period_ratio > param_fixed[\"period_bin_max\"]:\n",
    "        return -np.inf\n",
    "    # e must be <=1 => out_e <=0\n",
    "    if out_e > 0.0:\n",
    "        return -np.inf\n",
    "    if bin_name == \"e1\":\n",
    "        if out_e >= -2.0:\n",
    "            return -np.inf\n",
    "    elif bin_name == \"e2\":\n",
    "        if out_e < -2.0 or out_e > -1.5228:\n",
    "            return -np.inf\n",
    "    else:\n",
    "        if out_e <= -1.5228 or out_e > np.log10(0.08):\n",
    "            return -np.inf\n",
    "    # mass prior\n",
    "    mm = newD[\"out_m\"]\n",
    "    if mm < param_fixed[\"mass_prior_min\"] or mm > param_fixed[\"mass_prior_max\"]:\n",
    "        return -np.inf\n",
    "\n",
    "    # SSE from modelA\n",
    "    featA = [\"star_m\",\"inn_p\",\"inn_m\",\"inn_ecc\",\"inn_inc\",\"inn_omega\",\n",
    "             \"out_p\",\"out_m\",\"out_ecc\",\"out_inc\",\"out_omega\"]\n",
    "    rowA = [[ newD[\"star_m\"], newD[\"inn_p\"], newD[\"inn_m\"], newD[\"inn_ecc\"],\n",
    "              newD[\"inn_inc\"], newD[\"inn_omega\"],\n",
    "              newD[\"out_p\"], newD[\"out_m\"], newD[\"out_ecc\"],\n",
    "              newD[\"out_inc\"], newD[\"out_omega\"] ]]\n",
    "    X_dfA = pd.DataFrame(rowA, columns=featA)\n",
    "    X_scA = scA.transform(X_dfA)\n",
    "    pred_ = modelA.predict(X_scA)[0]\n",
    "    da = pred_[0] - actual_amp\n",
    "    df = pred_[1] - actual_freq\n",
    "    sse = da**2 + df**2\n",
    "    return -0.5 * sse\n",
    "\n",
    "###############################################################################\n",
    "# MCMC function with per-cluster Gelman-Rubin convergence diagnostics and\n",
    "# computation of an evidence estimate (lnZ) for Bayes factor comparisons.\n",
    "###############################################################################\n",
    "def do_mcmc_3param_layer1(period_bin, bin_name, old_param,\n",
    "                          start_p, p_std, start_m, start_e,\n",
    "                          modelA, scA,\n",
    "                          actual_amp, actual_freq,\n",
    "                          nsteps=400, nwalkers=30):\n",
    "    param_fixed = copy.deepcopy(old_param)\n",
    "    # Set period bin limits based on the period_bin argument\n",
    "    if period_bin == \"p1\":\n",
    "        param_fixed[\"period_bin_min\"] = 1.9;   param_fixed[\"period_bin_max\"] = 1.99\n",
    "    elif period_bin == \"p2\":\n",
    "        param_fixed[\"period_bin_min\"] = 2.01;  param_fixed[\"period_bin_max\"] = 2.1\n",
    "    elif period_bin == \"p3\":\n",
    "        param_fixed[\"period_bin_min\"] = 1.4;   param_fixed[\"period_bin_max\"] = 1.49\n",
    "    elif period_bin == \"p4\":\n",
    "        param_fixed[\"period_bin_min\"] = 1.51;  param_fixed[\"period_bin_max\"] = 1.6\n",
    "    elif period_bin == \"p5\":\n",
    "        param_fixed[\"period_bin_min\"] = 2.2;   param_fixed[\"period_bin_max\"] = 2.5\n",
    "    else:\n",
    "        param_fixed[\"period_bin_min\"] = 2.5;   param_fixed[\"period_bin_max\"] = 2.8\n",
    "\n",
    "    param_fixed[\"period_prior_min\"] = start_p - 3.0 * p_std\n",
    "    param_fixed[\"period_prior_max\"] = start_p + 3.0 * p_std\n",
    "    param_fixed[\"mass_prior_min\"]   = max((1.0/3.0)*start_m, 0.0)\n",
    "    param_fixed[\"mass_prior_max\"]   = min(3.0*start_m, 50.0)\n",
    "\n",
    "    def local_logprob(theta_):\n",
    "        return log_prob_3params_layer1(theta_, bin_name, param_fixed,\n",
    "                                       modelA, scA,\n",
    "                                       actual_amp, actual_freq)\n",
    "\n",
    "    ndim = 3\n",
    "    n_cluster = int(np.ceil(nwalkers * 0.7))\n",
    "    n_uniform = nwalkers - n_cluster\n",
    "\n",
    "    # Initialize period (p)\n",
    "    p_allowed_min = old_param[\"inn_p\"] * param_fixed[\"period_bin_min\"]\n",
    "    p_allowed_max = old_param[\"inn_p\"] * param_fixed[\"period_bin_max\"]\n",
    "    p_cluster = start_p + 0.1*np.random.randn(n_cluster)\n",
    "    p_cluster = np.clip(p_cluster, p_allowed_min, p_allowed_max)\n",
    "    if n_uniform >= 2:\n",
    "        p_uniform_random = np.random.uniform(p_allowed_min, p_allowed_max, size=n_uniform-2)\n",
    "        p_uniform = np.concatenate(([p_allowed_min, p_allowed_max], p_uniform_random))\n",
    "    else:\n",
    "        p_uniform = np.random.uniform(p_allowed_min, p_allowed_max, size=n_uniform)\n",
    "    p_init = np.concatenate([p_cluster, p_uniform])\n",
    "    np.random.shuffle(p_init)\n",
    "\n",
    "    # Initialize eccentricity (e)\n",
    "    if bin_name==\"e1\":\n",
    "        lower_e, upper_e = -9.0, -2.001\n",
    "    elif bin_name==\"e2\":\n",
    "        lower_e, upper_e = -2.0, -1.5228\n",
    "    else:\n",
    "        lower_e, upper_e = -1.5228, np.log10(0.08)\n",
    "    e_cluster = start_e + 0.1*np.random.randn(n_cluster)\n",
    "    e_cluster = np.clip(e_cluster, lower_e, upper_e)\n",
    "    if n_uniform >= 2:\n",
    "        e_uniform_random = np.random.uniform(lower_e, upper_e, size=n_uniform-2)\n",
    "        e_uniform = np.concatenate(([lower_e, upper_e], e_uniform_random))\n",
    "    else:\n",
    "        e_uniform = np.random.uniform(lower_e, upper_e, size=n_uniform)\n",
    "    e_init = np.concatenate([e_cluster, e_uniform])\n",
    "    np.random.shuffle(e_init)\n",
    "\n",
    "    # Initialize mass (m)\n",
    "    m_cluster = start_m + (np.random.rand(n_cluster)-0.5)*8\n",
    "    m_cluster = np.clip(m_cluster, param_fixed[\"mass_prior_min\"], param_fixed[\"mass_prior_max\"])\n",
    "    m_uniform = np.random.uniform(param_fixed[\"mass_prior_min\"], param_fixed[\"mass_prior_max\"], size=n_uniform)\n",
    "    m_init = np.concatenate([m_cluster, m_uniform])\n",
    "    np.random.shuffle(m_init)\n",
    "\n",
    "    pos0 = np.column_stack((p_init, e_init, m_init))\n",
    "    print(\"\\n=== do_mcmc_3param_layer1 => initial setup ===\")\n",
    "    print(f\"  period_bin={period_bin}, e-bin={bin_name}\")\n",
    "    print(f\"  start_p={start_p:.6f}, p_std={p_std:.6f}, start_m={start_m:.6f}, start_e={start_e:.6f}\")\n",
    "    print(f\"  period_prior=[{param_fixed['period_prior_min']:.6f}..{param_fixed['period_prior_max']:.6f}]\")\n",
    "    print(f\"  period_bin_range=[{param_fixed['period_bin_min']:.6f}..{param_fixed['period_bin_max']:.6f}]\")\n",
    "    print(f\"  mass_prior=[{param_fixed['mass_prior_min']:.6f}..{param_fixed['mass_prior_max']:.6f}]\")\n",
    "    for i, pos_ in enumerate(pos0):\n",
    "        print(f\"    walker {i}: p={pos_[0]:.6f}, e={pos_[1]:.6f}, m={pos_[2]:.6f}\")\n",
    "\n",
    "    # Evaluate the log-probability at each initial walker position\n",
    "    log_probs = np.array([local_logprob(pos) for pos in pos0])\n",
    "    print(\"Initial log probabilities:\", log_probs)\n",
    "    \n",
    "    # Optionally, check if any of the log probabilities are -inf (i.e., rejected)\n",
    "    if not np.all(np.isfinite(log_probs)):\n",
    "        print(\"Warning: Some initial log probabilities are -inf. Adjust your priors or initial guesses.\")\n",
    "    \n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, local_logprob, a = 1)\n",
    "    sampler.run_mcmc(pos0, nsteps, progress=True)\n",
    "\n",
    "    # Plot chain traces (convert eccentricity to linear scale for plotting)\n",
    "    chain_all = sampler.get_chain()\n",
    "    chain_plot = chain_all.copy()\n",
    "    chain_plot[:,:,1] = 10**(chain_plot[:,:,1])\n",
    "    fig_chain, axes_chain = plt.subplots(ndim,1, figsize=(6,6), sharex=True)\n",
    "    labels_3 = [\"out_p\",\"out_e\",\"out_m\"]\n",
    "    for d in range(ndim):\n",
    "        axes_chain[d].plot(chain_plot[:,:,d], alpha=0.5)\n",
    "        axes_chain[d].set_ylabel(labels_3[d])\n",
    "    axes_chain[-1].set_xlabel(\"Step\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # --- NEW: Compute and print SSE after chain plot ---\n",
    "    chain_post_temp = sampler.get_chain(discard=nsteps//2, thin=2)\n",
    "    chain_flat_temp = chain_post_temp.reshape(-1, ndim).copy()\n",
    "    overall_mean = np.mean(chain_flat_temp, axis=0)\n",
    "    overall_p = overall_mean[0]\n",
    "    overall_e_lin = overall_mean[1]\n",
    "    overall_m = overall_mean[2]\n",
    "    if overall_e_lin <= 1e-12:\n",
    "        overall_e_log = -9.0\n",
    "    else:\n",
    "        overall_e_log = np.log10(overall_e_lin)\n",
    "    newD_final = copy.deepcopy(param_fixed)\n",
    "    newD_final[\"out_p\"] = overall_p\n",
    "    newD_final[\"out_ecc\"] = overall_e_log\n",
    "    newD_final[\"out_m\"] = overall_m\n",
    "    featA = [\"star_m\",\"inn_p\",\"inn_m\",\"inn_ecc\",\"inn_inc\",\"inn_omega\",\n",
    "             \"out_p\",\"out_m\",\"out_ecc\",\"out_inc\",\"out_omega\"]\n",
    "    rowA_ = [[ newD_final[\"star_m\"], newD_final[\"inn_p\"], newD_final[\"inn_m\"], newD_final[\"inn_ecc\"],\n",
    "               newD_final[\"inn_inc\"], newD_final[\"inn_omega\"],\n",
    "               newD_final[\"out_p\"], newD_final[\"out_m\"], newD_final[\"out_ecc\"],\n",
    "               newD_final[\"out_inc\"], newD_final[\"out_omega\"] ]]\n",
    "    X_dfA_ = pd.DataFrame(rowA_, columns=featA)\n",
    "    X_scA_ = scA.transform(X_dfA_)\n",
    "    pred__ = modelA.predict(X_scA_)[0]\n",
    "    da_ = pred__[0] - actual_amp\n",
    "    df_ = pred__[1] - actual_freq\n",
    "    sse_ = da_**2 + df_**2\n",
    "    print(f\"Chain plot SSE = {sse_:.6f}\")\n",
    "    # --- END NEW ---\n",
    "\n",
    "    # Get post burn-in chain in 3D: shape (n_steps_post, n_walkers, ndim)\n",
    "    chain_post = sampler.get_chain(discard=nsteps//2, thin=2)\n",
    "    # Flatten for clustering; note we convert eccentricity to linear scale for clustering.\n",
    "    chain_flat = chain_post.reshape(-1, ndim).copy()\n",
    "    chain_for_clust = chain_flat.copy()\n",
    "    chain_for_clust[:,1] = 10**(chain_for_clust[:,1])\n",
    "\n",
    "    # Cluster the flattened chain using DBSCAN\n",
    "    clusters = cluster_mcmc_samples(chain_for_clust, eps=0.4, min_samples=500)\n",
    "    print(\"\\n=== DBSCAN clustering results ===\")\n",
    "    for iC, c_ in enumerate(clusters):\n",
    "        print(f\"Cluster {iC}: {c_['n_samples']} samples\")\n",
    "        # Compute Gelman-Rubin for this cluster separately:\n",
    "        rhat_cluster = gelman_rubin_cluster(chain_post, c_[\"indices\"], nwalkers)\n",
    "        if rhat_cluster is not None:\n",
    "            print(f\"  Cluster {iC} Gelman-Rubin R̂: {rhat_cluster}\")\n",
    "        else:\n",
    "            print(f\"  Cluster {iC}: Not enough samples per walker to compute R̂ reliably.\")\n",
    "    if not clusters:\n",
    "        print(\"No clusters => fallback to overall chain mean.\")\n",
    "        rhat_all = gelman_rubin(chain_post)  # --- NEW: Compute overall R̂ ---\n",
    "        print(f\"Overall chain Gelman-Rubin R̂: {rhat_all}\")  # --- NEW: Print overall R̂ ---\n",
    "        mean_ = np.mean(chain_flat, axis=0)\n",
    "        std_  = np.std(chain_flat, axis=0)\n",
    "        clusters = [{\"mean\": mean_, \"std\": std_, \"n_samples\": len(chain_flat),\n",
    "                     \"indices\": np.arange(len(chain_flat))}]\n",
    "    \n",
    "    solutions = []\n",
    "    for c_ in clusters:\n",
    "        p_mean = c_[\"mean\"][0]\n",
    "        p_std_ = c_[\"std\"][0]\n",
    "        m_mean = c_[\"mean\"][2]\n",
    "        m_std_ = c_[\"std\"][2]\n",
    "        mean_lin_e = c_[\"mean\"][1]\n",
    "        std_lin_e  = c_[\"std\"][1]\n",
    "        if mean_lin_e<=1e-12:\n",
    "            mean_log_e = -9.0\n",
    "            std_log_e  = 0.0\n",
    "        else:\n",
    "            mean_log_e = np.log10(mean_lin_e)\n",
    "            std_log_e  = std_lin_e / (mean_lin_e*np.log(10)) if mean_lin_e>0 else 0.0\n",
    "\n",
    "        # TTV predictions for each sample in cluster\n",
    "        indices_ = c_[\"indices\"]\n",
    "        cluster_samples_log = chain_flat[indices_]\n",
    "        ttv_preds = []\n",
    "        for samp_ in cluster_samples_log:\n",
    "            newD_ = copy.deepcopy(param_fixed)\n",
    "            newD_[\"out_p\"]   = samp_[0]\n",
    "            newD_[\"out_ecc\"] = samp_[1]\n",
    "            newD_[\"out_m\"]   = samp_[2]\n",
    "            featA = [\"star_m\",\"inn_p\",\"inn_m\",\"inn_ecc\",\"inn_inc\",\"inn_omega\",\n",
    "                     \"out_p\",\"out_m\",\"out_ecc\",\"out_inc\",\"out_omega\"]\n",
    "            rowA = [[ newD_[\"star_m\"], newD_[\"inn_p\"], newD_[\"inn_m\"], newD_[\"inn_ecc\"],\n",
    "                      newD_[\"inn_inc\"], newD_[\"inn_omega\"],\n",
    "                      newD_[\"out_p\"], newD_[\"out_m\"], newD_[\"out_ecc\"],\n",
    "                      newD_[\"out_inc\"], newD_[\"out_omega\"] ]]\n",
    "            X_dfA = pd.DataFrame(rowA, columns=featA)\n",
    "            X_scA = scA.transform(X_dfA)\n",
    "            pred_ = modelA.predict(X_scA)[0]\n",
    "            ttv_preds.append(pred_)\n",
    "        ttv_preds = np.array(ttv_preds)\n",
    "        predAmp_mean = np.mean(ttv_preds[:,0])\n",
    "        predAmp_std  = np.std(ttv_preds[:,0])\n",
    "        predDomP_mean = np.mean(ttv_preds[:,1])\n",
    "        predDomP_std = np.std(ttv_preds[:,1])\n",
    "\n",
    "        newD_final = copy.deepcopy(param_fixed)\n",
    "        newD_final[\"out_p\"]   = p_mean\n",
    "        newD_final[\"out_ecc\"] = mean_log_e\n",
    "        newD_final[\"out_m\"]   = m_mean\n",
    "        newD_final[\"predAmp\"] = predAmp_mean\n",
    "        newD_final[\"predDomP\"] = predDomP_mean\n",
    "\n",
    "        # Compute SSE\n",
    "        featA = [\"star_m\",\"inn_p\",\"inn_m\",\"inn_ecc\",\"inn_inc\",\"inn_omega\",\n",
    "                 \"out_p\",\"out_m\",\"out_ecc\",\"out_inc\",\"out_omega\"]\n",
    "        rowA_ = [[ newD_final[\"star_m\"], newD_final[\"inn_p\"], newD_final[\"inn_m\"], newD_final[\"inn_ecc\"],\n",
    "                   newD_final[\"inn_inc\"], newD_final[\"inn_omega\"],\n",
    "                   newD_final[\"out_p\"], newD_final[\"out_m\"], newD_final[\"out_ecc\"],\n",
    "                   newD_final[\"out_inc\"], newD_final[\"out_omega\"] ]]\n",
    "        X_dfA_ = pd.DataFrame(rowA_, columns=featA)\n",
    "        X_scA_ = scA.transform(X_dfA_)\n",
    "        pred__ = modelA.predict(X_scA_)[0]\n",
    "        da_ = pred__[0] - actual_amp\n",
    "        df_ = pred__[1] - actual_freq\n",
    "        sse_ = da_**2 + df_**2\n",
    "\n",
    "        solutions.append({\"final_param_dict\": newD_final,\n",
    "                          \"p_mean\": (p_mean, p_std_),\n",
    "                          \"e_mean\": (mean_log_e, std_log_e),\n",
    "                          \"mass_mean\": (m_mean, m_std_),\n",
    "                          \"ttvAmp\": (predAmp_mean, predAmp_std),\n",
    "                          \"ttvDomP\": (predDomP_mean, predDomP_std),\n",
    "                          \"SSE\": sse_})\n",
    "    print(\"\\nConvergence solutions for this bin combo:\")\n",
    "    for iSol, sol_ in enumerate(solutions):\n",
    "        fd = sol_[\"final_param_dict\"]\n",
    "        p_val, p_err = sol_[\"p_mean\"]\n",
    "        m_val, m_err = sol_[\"mass_mean\"]\n",
    "        e_log, e_err = sol_[\"e_mean\"]\n",
    "        e_val = 10**(e_log)\n",
    "        e_err_lin = 10**(e_log + e_err) - 10**(e_log) if e_val>1e-12 else 0.0\n",
    "        ttv_amp, ttv_amp_err = sol_[\"ttvAmp\"]\n",
    "        ttv_domP, ttv_domP_err = sol_[\"ttvDomP\"]\n",
    "        sse_ = sol_[\"SSE\"]\n",
    "        print(f\"  Solution {iSol}:\")\n",
    "        print(f\"    Outer Period = {p_val:.6f} ± {p_err:.6f}\")\n",
    "        print(f\"    Outer Mass   = {m_val:.6f} ± {m_err:.6f}\")\n",
    "        print(f\"    Outer Ecc (linear) = {e_val:.6f} ± {e_err_lin:.6f}\")\n",
    "        print(f\"    Predicted TTV Amp   = {ttv_amp:.6f} ± {ttv_amp_err:.6f}\")\n",
    "        print(f\"    Predicted TTV DomP  = {ttv_domP:.6f} ± {ttv_domP_err:.6f}\")\n",
    "        print(f\"    SSE = {sse_:.6f}\\n\")\n",
    "\n",
    "    # --- NEW: Compute Bayesian evidence using a harmonic mean estimator ---\n",
    "    log_prob_post = sampler.get_log_prob(discard=nsteps//2, thin=2, flat=True)\n",
    "    log_prob_post = log_prob_post[np.isfinite(log_prob_post)]\n",
    "    if len(log_prob_post) > 0:\n",
    "        L_values = np.exp(log_prob_post)\n",
    "        Z_est = 1.0 / np.mean(1.0 / L_values)\n",
    "        lnZ = np.log(Z_est)\n",
    "    else:\n",
    "        lnZ = -np.inf\n",
    "    print(f\"Estimated log evidence (lnZ) = {lnZ:.6f}\")\n",
    "    # --- END NEW ---\n",
    "\n",
    "    # Corner plots for visualization (unchanged)\n",
    "    p_min, p_max = np.min(chain_flat[:,0]), np.max(chain_flat[:,0])\n",
    "    m_min, m_max = np.min(chain_flat[:,2]), np.max(chain_flat[:,2])\n",
    "    pad_p = 0.1*(p_max-p_min)\n",
    "    pad_m = 0.1*(m_max-m_min)\n",
    "    full_range = [(p_min-pad_p, p_max+pad_p),\n",
    "                  (np.min(10**(chain_flat[:,1])), np.max(10**(chain_flat[:,1]))),\n",
    "                  (m_min-pad_m, m_max+pad_m)]\n",
    "    chain_flat_for_corner = chain_flat.copy()\n",
    "    chain_flat_for_corner[:,1] = 10**(chain_flat_for_corner[:,1])\n",
    "    labels_3 = [\"out_p\",\"out_e\",\"out_m\"]\n",
    "\n",
    "    fig_corner_all = corner.corner(chain_flat_for_corner,\n",
    "                                   labels=labels_3,\n",
    "                                   bins=50,\n",
    "                                   range=full_range,\n",
    "                                   color='red',\n",
    "                                   show_titles=True,\n",
    "                                   title_fmt=\".3f\")\n",
    "    plt.title(\"Corner Plot: All Samples\")\n",
    "    plt.show()\n",
    "\n",
    "    fig_heat = corner.corner(chain_flat_for_corner,\n",
    "                             labels=labels_3,\n",
    "                             bins=50,\n",
    "                             range=full_range,\n",
    "                             plot_density=True,\n",
    "                             plot_datapoints=False,\n",
    "                             smooth=1,\n",
    "                             smooth1d=1,\n",
    "                             fill_contours=True,\n",
    "                             contour_kwargs={},\n",
    "                             color=None,\n",
    "                             show_titles=True,\n",
    "                             title_fmt=\".3f\")\n",
    "    #plt.title(\"Corner Plot\")\n",
    "    plt.show()\n",
    "\n",
    "    chain_flat_post = sampler.get_chain(discard=nsteps//2, thin=2, flat=True).copy()\n",
    "    chain_flat_post[:,1] = 10**(chain_flat_post[:,1])\n",
    "    fig_corner_post = corner.corner(chain_flat_post,\n",
    "                                    labels=labels_3,\n",
    "                                    bins=50,\n",
    "                                    range=full_range,\n",
    "                                    color='blue',\n",
    "                                    show_titles=True,\n",
    "                                    title_fmt=\".3f\")\n",
    "    plt.title(\"Corner Plot: Post Burn-In\")\n",
    "    plt.show()\n",
    "\n",
    "    return solutions, lnZ\n",
    "\n",
    "###############################################################################\n",
    "# SINGLE-LAYER pipeline\n",
    "###############################################################################\n",
    "def run_singlelayer_pipeline_for_system(sysdict, modelB_map, modelA_map):\n",
    "    baseParam = copy.deepcopy(sysdict)\n",
    "    combos_e = {}\n",
    "    period_bins = [\"p1\",\"p2\",\"p3\",\"p4\",\"p5\",\"p6\"]\n",
    "    ecc_bins = [\"e1\",\"e2\",\"e3\"]\n",
    "    for pbin in period_bins:\n",
    "        for ebin in ecc_bins:\n",
    "            (rfB, scB, errB) = modelB_map.get((pbin, ebin),(None,None,None))\n",
    "            if rfB is None:\n",
    "                if pbin==\"p1\":\n",
    "                    guess_p = baseParam[\"inn_p\"]*1.95\n",
    "                elif pbin==\"p2\":\n",
    "                    guess_p = baseParam[\"inn_p\"]*2.05\n",
    "                elif pbin==\"p3\":\n",
    "                    guess_p = baseParam[\"inn_p\"]*1.445\n",
    "                elif pbin==\"p4\":\n",
    "                    guess_p = baseParam[\"inn_p\"]*1.555\n",
    "                elif pbin==\"p5\":\n",
    "                    guess_p = baseParam[\"inn_p\"]*2.35\n",
    "                else:\n",
    "                    guess_p = baseParam[\"inn_p\"]*2.65\n",
    "                guess_m = 10.0\n",
    "            else:\n",
    "                featB = [\"star_m\",\"inn_p\",\"inn_m\",\"inn_ecc\",\"inn_inc\",\"inn_omega\",\"AmpP1\",\"DomP1\"]\n",
    "                rowB = [[ baseParam[\"star_m\"], baseParam[\"inn_p\"], baseParam[\"inn_m\"],\n",
    "                          baseParam[\"inn_ecc\"], baseParam[\"inn_inc\"], baseParam[\"inn_omega\"],\n",
    "                          baseParam[\"AmpP1\"], baseParam[\"DomP1\"] ]]\n",
    "                X_dfB = pd.DataFrame(rowB, columns=featB)\n",
    "                X_scB = scB.transform(X_dfB)\n",
    "                outB_ = rfB.predict(X_scB)[0]\n",
    "                guess_m = outB_[0]\n",
    "                guess_p = outB_[1]\n",
    "            p_std_for_mcmc = 0.05*guess_p\n",
    "            if p_std_for_mcmc<1e-6:\n",
    "                p_std_for_mcmc = max(0.5, 0.05*baseParam[\"inn_p\"])\n",
    "            if ebin==\"e1\":\n",
    "                guess_e = -2.5\n",
    "            elif ebin==\"e2\":\n",
    "                guess_e = -1.8\n",
    "            else:\n",
    "                guess_e = -1.3\n",
    "            (rfA, scA, errA) = modelA_map.get((pbin, ebin),(None,None,None))\n",
    "            sol_list, lnZ = do_mcmc_3param_layer1(\n",
    "                period_bin=pbin, bin_name=ebin, old_param=baseParam,\n",
    "                start_p=guess_p, p_std=p_std_for_mcmc,\n",
    "                start_m=guess_m, start_e=guess_e,\n",
    "                modelA=rfA, scA=scA,\n",
    "                actual_amp=baseParam[\"AmpP1\"], actual_freq=baseParam[\"DomP1\"],\n",
    "                nsteps=400, nwalkers=40\n",
    "            )\n",
    "            combos_e[(pbin,ebin)] = {\"solutions\": sol_list, \"lnZ\": lnZ, \"errA\": errA, \"errB\": errB}\n",
    "    combos_final=[]\n",
    "    for (pbin,ebin), results in combos_e.items():\n",
    "        combos_final.append({\"bins\":(pbin,ebin), \"solutions\": results[\"solutions\"], \"lnZ\": results[\"lnZ\"],\n",
    "                             \"errA\": results[\"errA\"], \"errB\": results[\"errB\"]})\n",
    "    return combos_final\n",
    "\n",
    "###############################################################################\n",
    "# 3D / scatter plot helpers (unchanged)\n",
    "###############################################################################\n",
    "def set_3d_axes_and_reverse_mass(ax):\n",
    "    x1,x2= ax.get_xlim3d()\n",
    "    y1,y2= ax.get_ylim3d()\n",
    "    z1,z2= ax.get_zlim3d()\n",
    "    ax.set_xlim3d(x1,x2)\n",
    "    ax.set_ylim3d(y2,y1)\n",
    "    ax.set_zlim3d(z1,z2)\n",
    "\n",
    "def reverse_mass_axis_plotly(fig):\n",
    "    fig.update_layout(scene=dict(yaxis=dict(autorange=\"reversed\")))\n",
    "\n",
    "def three_3d_diff_plots_with_mass_reversed(X,Y,Z, title_extra=\"\"):\n",
    "    fig1= plt.figure()\n",
    "    ax1= fig1.add_subplot(111, projection='3d')\n",
    "    ax1.scatter(X,Y,Z, c='b', marker='o')\n",
    "    ax1.set_xlabel(\"X\")\n",
    "    ax1.set_ylabel(\"Y (mass reversed)\")\n",
    "    ax1.set_zlabel(\"Z\")\n",
    "    ax1.set_title(f\"3D Scatter {title_extra}\")\n",
    "    plt.draw()\n",
    "    set_3d_axes_and_reverse_mass(ax1)\n",
    "    plt.show()\n",
    "    if len(X)>=3:\n",
    "        fig2= plt.figure()\n",
    "        ax2= fig2.add_subplot(111, projection='3d')\n",
    "        ax2.plot_trisurf(X,Y,Z, edgecolor='gray', linewidth=0.2, alpha=0.5)\n",
    "        ax2.set_xlabel(\"X\")\n",
    "        ax2.set_ylabel(\"Y (mass reversed)\")\n",
    "        ax2.set_zlabel(\"Z\")\n",
    "        ax2.set_title(f\"3D Wire/TriSurf {title_extra}\")\n",
    "        plt.draw()\n",
    "        set_3d_axes_and_reverse_mass(ax2)\n",
    "        plt.show()\n",
    "    fig3= px.scatter_3d(x=X, y=Y, z=Z, title=f\"Interactive 3D {title_extra}\")\n",
    "    reverse_mass_axis_plotly(fig3)\n",
    "    fig3.show()\n",
    "\n",
    "def plot_3d_actual_pred_rev(p_act, m_act, e_act, p_pred, m_pred, e_pred, sys_idx):\n",
    "    X= [p_act, p_pred]\n",
    "    Y= [m_act, m_pred]\n",
    "    Z= [e_act, e_pred]\n",
    "    figA= plt.figure()\n",
    "    axA= figA.add_subplot(111, projection='3d')\n",
    "    axA.scatter([p_act],[m_act],[e_act], c='b', s=50, label='Actual')\n",
    "    axA.scatter([p_pred],[m_pred],[e_pred], c='r', s=50, label='Predicted')\n",
    "    axA.set_xlabel(\"Period\")\n",
    "    axA.set_ylabel(\"Mass (reversed)\")\n",
    "    axA.set_zlabel(\"Ecc\")\n",
    "    axA.set_title(f\"System {sys_idx} => 3D scatter reversed mass\")\n",
    "    plt.draw()\n",
    "    set_3d_axes_and_reverse_mass(axA)\n",
    "    axA.legend()\n",
    "    plt.show()\n",
    "\n",
    "    figB= plt.figure()\n",
    "    axB= figB.add_subplot(111, projection='3d')\n",
    "    axB.plot(X,Y,Z, c='gray')\n",
    "    axB.scatter([p_act],[m_act],[e_act], c='b', s=50, label='Actual')\n",
    "    axB.scatter([p_pred],[m_pred],[e_pred], c='r', s=50, label='Predicted')\n",
    "    axB.set_xlabel(\"Period\")\n",
    "    axB.set_ylabel(\"Mass (reversed)\")\n",
    "    axB.set_zlabel(\"Ecc\")\n",
    "    axB.set_title(f\"System {sys_idx} => wire reversed mass\")\n",
    "    plt.draw()\n",
    "    set_3d_axes_and_reverse_mass(axB)\n",
    "    axB.legend()\n",
    "    plt.show()\n",
    "\n",
    "    df_plot= pd.DataFrame({\"Period\":X,\"Mass\":Y,\"Ecc\":Z,\"Type\":[\"Actual\",\"Predicted\"]})\n",
    "    figC= px.scatter_3d(df_plot, x=\"Period\", y=\"Mass\", z=\"Ecc\", color=\"Type\",\n",
    "                        symbol=\"Type\", title=f\"System {sys_idx} => interactive reversed mass\")\n",
    "    reverse_mass_axis_plotly(figC)\n",
    "    figC.show()\n",
    "\n",
    "def single_scatter(paramName, dataList):\n",
    "    if not dataList:\n",
    "        return\n",
    "    x_ = [d[0] for d in dataList]\n",
    "    y_ = [d[1] for d in dataList]\n",
    "    e_ = [d[2] for d in dataList]\n",
    "    plt.figure()\n",
    "    plt.errorbar(x_, y_, yerr=e_, fmt='o', color='k', ecolor='red', capsize=3)\n",
    "    mn = min(min(x_), min(y_))\n",
    "    mx = max(max(x_), max(y_))\n",
    "    plt.plot([mn,mx],[mn,mx],'r--')\n",
    "    plt.xlabel(f\"Actual {paramName}\")\n",
    "    plt.ylabel(f\"Pred {paramName}\")\n",
    "    plt.title(f\"{paramName} => so far: {len(dataList)} systems\")\n",
    "    plt.show()\n",
    "\n",
    "###############################################################################\n",
    "# MAIN\n",
    "###############################################################################\n",
    "def main():\n",
    "    print(\"=== LOADING & PREPARING MAIN DATA ===\")\n",
    "    df_all = pd.read_csv(\"E:/SIMS92/ttv_dataset_multiple_params.csv\")\n",
    "\n",
    "    rename_map = {\n",
    "        \"Stellar Mass (Msun)\": \"star_m\",\n",
    "        \"Inner Period (days)\": \"inn_p\",\n",
    "        \"Inner Mass (Mearth)\": \"inn_m\",\n",
    "        \"Inner Eccentricity\": \"inn_ecc\",\n",
    "        \"Inner Inclination\": \"inn_inc\",\n",
    "        \"Inner Omega\": \"inn_omega\",\n",
    "        \"Outer Mass (Mearth)\": \"out_m\",\n",
    "        \"Outer Period (days)\": \"out_p\",\n",
    "        \"Outer Eccentricity\": \"out_ecc\",\n",
    "        \"Outer Inclination\": \"out_inc\",\n",
    "        \"Outer Omega\": \"out_omega\",\n",
    "        \"Amplitude of Dominant Period Test (P1)\": \"AmpP1\",\n",
    "        \"Dominant Period Planet 1\": \"DomP1\"\n",
    "    }\n",
    "    df_all.rename(columns=rename_map, inplace=True, errors='ignore')\n",
    "\n",
    "    # Filter out large masses, clamp ecc, log-transform\n",
    "    df_all = df_all[df_all[\"out_m\"] <= 50].copy()\n",
    "    df_all[\"inn_ecc\"] = df_all[\"inn_ecc\"].clip(lower=0, upper=1.0)\n",
    "    df_all[\"out_ecc\"] = df_all[\"out_ecc\"].clip(lower=0, upper=1.0)\n",
    "    df_all[\"inn_ecc\"] = np.log10(df_all[\"inn_ecc\"].replace(0, 1e-9))\n",
    "    df_all[\"out_ecc\"] = np.log10(df_all[\"out_ecc\"].replace(0, 1e-9))\n",
    "\n",
    "    df_all[\"ratio\"] = df_all[\"out_p\"] / df_all[\"inn_p\"]\n",
    "\n",
    "    def ratio_in_any_period_bin(r):\n",
    "        return ((1.9<=r<=1.99) or (2.01<=r<=2.1) or\n",
    "                (1.4<=r<=1.49) or (1.51<=r<=1.6) or\n",
    "                (2.2<=r<=2.5) or (2.5<r<=2.8))\n",
    "    def ecc_in_any_bin(e_log):\n",
    "        e_lin=10**(e_log)\n",
    "        return ((0.0<=e_lin<=0.01) or (0.01<e_lin<=0.03) or (0.03< e_lin<=1.0))\n",
    "    mask_ratio = df_all[\"ratio\"].apply(ratio_in_any_period_bin)\n",
    "    mask_ecc   = df_all[\"out_ecc\"].apply(ecc_in_any_bin)\n",
    "    df_filtered= df_all[mask_ratio & mask_ecc].copy()\n",
    "\n",
    "    essential_cols= [\"star_m\",\"inn_p\",\"inn_m\",\"inn_ecc\",\"inn_inc\",\"inn_omega\",\n",
    "                     \"out_m\",\"out_p\",\"out_ecc\",\"out_inc\",\"out_omega\",\"AmpP1\",\"DomP1\",\"ratio\"]\n",
    "    df_filtered.dropna(subset=essential_cols, inplace=True)\n",
    "    df_filtered.reset_index(drop=True, inplace=True)\n",
    "    if len(df_filtered)==0:\n",
    "        print(\"No data remains after filtering => abort.\")\n",
    "        return\n",
    "\n",
    "    df_all= df_filtered\n",
    "    print(f\"Data filtered: {len(df_all)} rows remain.\\n\")\n",
    "\n",
    "    # Build the 18 models\n",
    "    df_tmp = df_all.copy()\n",
    "    period_bins = [\"p1\",\"p2\",\"p3\",\"p4\",\"p5\",\"p6\"]\n",
    "    ecc_bins    = [\"e1\",\"e2\",\"e3\"]\n",
    "    print(\"\\n=== Building ModelB for period and eccentricity bins ===\")\n",
    "    modelB_map={}\n",
    "    modelB_errors = []\n",
    "    for pb in period_bins:\n",
    "        for eb in ecc_bins:\n",
    "            rfB, scB, errB = build_modelB_for_bin(df_tmp, pb, eb)\n",
    "            modelB_map[(pb, eb)] = (rfB, scB, errB)\n",
    "            if errB is not None:\n",
    "                modelB_errors.append(errB)\n",
    "    print(\"\\n=== Building ModelA for period and eccentricity bins ===\")\n",
    "    modelA_map={}\n",
    "    modelA_errors = []\n",
    "    for pb in period_bins:\n",
    "        for eb in ecc_bins:\n",
    "            rfA, scA, errA = build_modelA_for_bin(df_tmp, pb, eb)\n",
    "            modelA_map[(pb, eb)] = (rfA, scA, errA)\n",
    "            if errA is not None:\n",
    "                modelA_errors.append(errA)\n",
    "\n",
    "    # Print overall aggregated error metrics for ModelA and ModelB (all bins)\n",
    "    if modelA_errors:\n",
    "        overall_A = {\"MAE\": np.mean([d[\"MAE\"] for d in modelA_errors]),\n",
    "                     \"RMSE\": np.mean([d[\"RMSE\"] for d in modelA_errors]),\n",
    "                     \"MAFE\": np.mean([d[\"MAFE\"] for d in modelA_errors]),\n",
    "                     \"R2\": np.mean([d[\"R2\"] for d in modelA_errors])}\n",
    "        print(\"\\nOverall aggregated errors for Model A (all bins):\")\n",
    "        print(overall_A)\n",
    "    if modelB_errors:\n",
    "        overall_B = {\"MAE\": np.mean([d[\"MAE\"] for d in modelB_errors]),\n",
    "                     \"RMSE\": np.mean([d[\"RMSE\"] for d in modelB_errors]),\n",
    "                     \"MAFE\": np.mean([d[\"MAFE\"] for d in modelB_errors]),\n",
    "                     \"R2\": np.mean([d[\"R2\"] for d in modelB_errors])}\n",
    "        print(\"\\nOverall aggregated errors for Model B (all bins):\")\n",
    "        print(overall_B)\n",
    "\n",
    "    # Now filter out bins with period p5 and p6 and compute again.\n",
    "    modelA_errors_filtered = [d for (k,d) in zip(modelA_map.keys(), modelA_errors) if k[0] not in {\"p5\",\"p6\"}]\n",
    "    modelB_errors_filtered = [d for (k,d) in zip(modelB_map.keys(), modelB_errors) if k[0] not in {\"p5\",\"p6\"}]\n",
    "    # Note: Because the errors lists were appended in the loop (in order of looping), an alternative is to loop over keys.\n",
    "    # Here we re-loop over the keys:\n",
    "    modelA_errors_filtered = []\n",
    "    for (pb, eb), (rfA, scA, errA) in modelA_map.items():\n",
    "        if pb not in {\"p5\", \"p6\"} and errA is not None:\n",
    "            modelA_errors_filtered.append(errA)\n",
    "    modelB_errors_filtered = []\n",
    "    for (pb, eb), (rfB, scB, errB) in modelB_map.items():\n",
    "        if pb not in {\"p5\", \"p6\"} and errB is not None:\n",
    "            modelB_errors_filtered.append(errB)\n",
    "\n",
    "    if modelA_errors_filtered:\n",
    "        overall_A_filtered = {\"MAE\": np.mean([d[\"MAE\"] for d in modelA_errors_filtered]),\n",
    "                              \"RMSE\": np.mean([d[\"RMSE\"] for d in modelA_errors_filtered]),\n",
    "                              \"MAFE\": np.mean([d[\"MAFE\"] for d in modelA_errors_filtered]),\n",
    "                              \"R2\": np.mean([d[\"R2\"] for d in modelA_errors_filtered])}\n",
    "        print(\"\\nOverall aggregated errors for Model A (bins excluding p5 and p6):\")\n",
    "        print(overall_A_filtered)\n",
    "    if modelB_errors_filtered:\n",
    "        overall_B_filtered = {\"MAE\": np.mean([d[\"MAE\"] for d in modelB_errors_filtered]),\n",
    "                              \"RMSE\": np.mean([d[\"RMSE\"] for d in modelB_errors_filtered]),\n",
    "                              \"MAFE\": np.mean([d[\"MAFE\"] for d in modelB_errors_filtered]),\n",
    "                              \"R2\": np.mean([d[\"R2\"] for d in modelB_errors_filtered])}\n",
    "        print(\"\\nOverall aggregated errors for Model B (bins excluding p5 and p6):\")\n",
    "        print(overall_B_filtered)\n",
    "\n",
    "    # Define a single system dictionary (using user-provided values)\n",
    "    user_system = {\n",
    "        \"star_m\": 0.97,\n",
    "        \"inn_m\": 17.3,\n",
    "        \"inn_p\": 7.64159,\n",
    "        \"inn_ecc\": np.log10(1e-9) if 0.0<=1e-12 else 0.0,\n",
    "        \"inn_inc\": 87.68,\n",
    "        \"inn_omega\": 0.0,\n",
    "        \"AmpP1\": 6.887061813,\n",
    "        \"DomP1\": 34.48248077,\n",
    "        \"out_m\": 16.4,\n",
    "        \"out_p\": 14.85888,\n",
    "        \"out_ecc\": np.log10(1e-9) if 0.0<=1e-12 else 0.0,\n",
    "        \"out_inc\": 88.07,\n",
    "        \"out_omega\": 0.0\n",
    "    }\n",
    "    #user_system[\"inn_ecc\"] = -9.0\n",
    "    #user_system[\"out_ecc\"] = -9.0\n",
    "    user_system[\"ratio\"] = user_system[\"out_p\"] / user_system[\"inn_p\"]\n",
    "\n",
    "    # Run the single-layer pipeline on the user system\n",
    "    combos_18 = run_singlelayer_pipeline_for_system(user_system, modelB_map, modelA_map)\n",
    "\n",
    "    print(\"\\n=== RESULTS for the single user-provided system ===\")\n",
    "    bayes_results = {}\n",
    "    for co in combos_18:\n",
    "        pbin, ebin = co[\"bins\"]\n",
    "        sol_list = co[\"solutions\"]\n",
    "        lnZ = co[\"lnZ\"]\n",
    "        bayes_results[(pbin, ebin)] = lnZ\n",
    "        print(f\"Bin=({pbin},{ebin}), #solutions={len(sol_list)}, lnZ = {lnZ:.6f}\")\n",
    "        for iSol, sol_ in enumerate(sol_list):\n",
    "            fd = sol_[\"final_param_dict\"]\n",
    "            p_val, p_err = sol_[\"p_mean\"]\n",
    "            m_val, m_err = sol_[\"mass_mean\"]\n",
    "            e_log, e_std = sol_[\"e_mean\"]\n",
    "            e_lin = 10**(e_log)\n",
    "            e_err_lin = 10**(e_log + e_std)- 10**(e_log) if e_lin>1e-12 else 0.0\n",
    "            a_val = fd[\"predAmp\"]\n",
    "            f_val = fd[\"predDomP\"]\n",
    "            sse_  = sol_[\"SSE\"]\n",
    "            print(f\"  solution {iSol}: out_p={p_val:.6f} ± {p_err:.6f}, \"\n",
    "                  f\"out_m={m_val:.6f} ± {m_err:.6f}, e_lin={e_lin:.6f} ± {e_err_lin:.6f}, \"\n",
    "                  f\"PredAmp={a_val:.6f}, PredDomP={f_val:.6f}, SSE={sse_:.6f}\")\n",
    "    # --- NEW: Compute and print Bayes factor differences (ΔlnZ) ---\n",
    "    if bayes_results:\n",
    "        best_lnZ = max(bayes_results.values())\n",
    "        print(\"\\n=== Bayes Factor (ΔlnZ) Summary ===\")\n",
    "        for bin_key, lnZ in bayes_results.items():\n",
    "            delta_lnZ = lnZ - best_lnZ\n",
    "            print(f\"Bin {bin_key}: lnZ = {lnZ:.6f}, ΔlnZ = {delta_lnZ:.6f}\")\n",
    "    # --- END NEW ---\n",
    "\n",
    "    print(\"\\nDone. You have the MCMC solutions for the single system.\")\n",
    "    print(\"No final difference plots are produced since we are only analyzing one system.\")\n",
    "    print(\"If you need additional plots, you can adapt the code above accordingly.\")\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
